# Sleep Project: The Ultimate Tour Guide

Welcome! This document is designed to take you from "I have no idea what this is" to "I understand every nut and bolt of this simulation." We will explore the project's purpose, its building blocks, and the logic that drives it.

---

## 1. What is this Project? (The Big Picture)

Imagine you are a sleep doctor trying to help patients improve their sleep quality. You have data for several patients (subjects), detailing their sleep patterns night by night. For each night, there are potential actions they could take (like "drink warm milk", "avoid screens", etc.), and each action has a predicted effect on their sleep stats.

This project is a **computer simulation** that acts like a "virtual brain" for these patients. It looks at their data, night by night, and decides the **best possible action** to take to reach a "perfect sleep state."

### Key Concepts
*   **The Goal:** Reach a "perfect" state where two metrics, **CSI** (Cumulative Sleep Index) and **CStab** (Circadian Stability), are both equal to **1.0**.
*   **The Agents:** Virtual representations of the patients.
*   **The Simulation:** A program that fast-forwards through time, making decisions for every patient simultaneously and recording the results.

---

## 2. The Tech Stack: Libraries & Tools

This project is built on **Python**. Here is the breakdown of the tools used and exactly where they fit in.

### A. Mesa (The Core Framework)
**What it is:** A library for Agent-Based Modeling (ABM). It provides the skeleton for creating agents and a world for them to live in.
**Where it is used:** `agent.py` and `model.py`.

*   **`mesa.Agent`** (`agent.py`):
    *   **Concept:** Think of this as the "Player Character" class.
    *   **In Code:** `class SubjectAgent(mesa.Agent):`
    *   **Function:** It gives our subjects a `unique_id` and the ability to exist in the model. We override the `step()` method to define what the agent *does* (thinks/acts) at every moment.

*   **`mesa.Model`** (`model.py`):
    *   **Concept:** This is the "Game World" or "God Object." It holds all the agents and manages time.
    *   **In Code:** `class SleepModel(mesa.Model):`
    *   **Function:** It loads the data, creates the agents, and tells them when to act.

*   **`mesa.time.SimultaneousActivation`** (`model.py`):
    *   **Concept:** The "Clock."
    *   **In Code:** `self.schedule = SimultaneousActivation(self)`
    *   **Function:** It ensures that when we say "Next Night," *every* agent moves to the next night at the exact same time.

*   **`mesa.DataCollector`** (`model.py`):
    *   **Concept:** The "Scoreboard" or "Statistician."
    *   **In Code:** `self.datacollector = mesa.DataCollector(...)`
    *   **Function:** It automatically grabs variables (like `current_CSI`) from every agent at every step so we can analyze them later.

### B. Matplotlib (The Artist)
**What it is:** A plotting library.
**Where it is used:** `run_simulation.py`.
**Function:** It takes the raw numbers generated by the simulation and draws the graphs (`csi_trend.png`, etc.) so you can visually see if the agents are improving.

### C. Standard Python Libraries
*   **`json`**: Reads the input files (the patient data).
*   **`glob` & `os`**: Finds the data files on your hard drive.
*   **`math`**: Used for the "Brain" (calculating distances).
*   **`csv`**: Saves the final results into a spreadsheet format.

---

## 3. How It Works: A Code Walkthrough

Let's trace the flow of execution from start to finish.

### Phase 1: Setup (`run_simulation.py` -> `model.py`)
1.  You run `run_simulation.py`.
2.  It creates an instance of `SleepModel`.
3.  **Inside `SleepModel.__init__`**:
    *   It looks in the `anomaly_state_files/subject_states` folder.
    *   It finds files like `subject_01_state.json`.
    *   For each file, it creates a `SubjectAgent` and hands it that specific patient's data.
    *   It adds the agent to the `schedule`.

### Phase 2: The Loop (`run_simulation.py`)
The simulation enters a `while` loop:
```python
while model.running:
    model.step()
```
This is the heartbeat of the program. It keeps ticking until the model says "I'm done" (`model.running = False`).

### Phase 3: The Brain (`agent.py`)
This is where the magic happens. Every time `model.step()` is called, it triggers `agent.step()` for every agent.

**Inside `SubjectAgent.step()`:**
1.  **Read Data:** The agent looks at the data for the *current night*.
2.  **Identify Options:** It sees a list of possible actions (e.g., "Action A", "Action B").
3.  **The Algorithm (Decision Making):** It calculates which action is best (explained in detail below).
4.  **Update State:** It updates its `current_CSI` and `current_CStab` based on the chosen action.
5.  **Record History:** It saves what happened into a list (`self.history`).
6.  **Time Travel:** It increments `current_night_index` to prepare for the next step.

### Phase 4: Wrap Up (`run_simulation.py`)
1.  The loop finishes.
2.  The code gathers `self.history` from all agents.
3.  It writes `simulation_results.csv`.
4.  It draws the charts.

---

## 4. The Algorithm: Greedy Best-First Search

The user asked for "A* (A-Star)," but because we process one night at a time without looking at future nights' data, the implementation is technically a **Greedy Best-First Search**.

### The Logic (Simple Terms)
Imagine you are standing in a field (your current state). You want to get to a specific tree (the Goal: 1.0, 1.0). You can take one of several steps (Actions).
1.  You look at where "Step A" would land you.
2.  You look at where "Step B" would land you.
3.  You measure the distance from those landing spots to the tree.
4.  You take the step that lands you closest to the tree.

### The Implementation (Code Detail)
Located in `agent.py`, inside the `step` method:

1.  **The Goal:**
    ```python
    target_CSI = 1.0
    target_CStab = 1.0
    ```

2.  **The Loop (Evaluating Options):**
    The code loops through every available action for that night:
    ```python
    for action, effects in action_effects.items():
    ```

3.  **The Prediction:**
    It calculates "What if I take this action?"
    ```python
    predicted_CSI = self.current_CSI + dCSI
    predicted_CStab = self.current_CStab + dCStab
    ```

4.  **The Heuristic (The Math):**
    It uses the **Euclidean Distance Formula** (Pythagoras' Theorem) to measure how far the predicted state is from the goal.
    $$ Distance = \sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2} $$
    
    In Python:
    ```python
    distance = math.sqrt((predicted_CSI - target_CSI)**2 + (predicted_CStab - target_CStab)**2)
    ```

5.  **The Choice:**
    It keeps track of the smallest distance found so far (`min_distance`). If the current action's distance is smaller, it becomes the new `best_action`.

### Why is this "Greedy"?
It is "greedy" because it only cares about the *immediate* benefit. It doesn't ask "If I take a bad step now, will it open up a shortcut tomorrow?" It simply takes the best possible step available *right now*.

---

## Summary
*   **Mesa** provides the structure (Agents, Model, Time).
*   **Python** handles the logic and file I/O.
*   **The Algorithm** is a distance-minimizing search that looks at all options for the current night and picks the one that gets the metrics closest to 1.0.
